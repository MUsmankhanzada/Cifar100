{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "935hjRcQXMZW",
        "outputId": "d6dff570-2ca9-4944-afa3-384c146f1892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting torch (from efficientnet_pytorch)\n",
            "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in d:\\anaconda\\envs\\testenv\\lib\\site-packages (from torch->efficientnet_pytorch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\anaconda\\envs\\testenv\\lib\\site-packages (from torch->efficientnet_pytorch) (4.12.2)\n",
            "Collecting networkx (from torch->efficientnet_pytorch)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->efficientnet_pytorch)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fsspec in d:\\anaconda\\envs\\testenv\\lib\\site-packages (from torch->efficientnet_pytorch) (2024.9.0)\n",
            "Requirement already satisfied: setuptools in d:\\anaconda\\envs\\testenv\\lib\\site-packages (from torch->efficientnet_pytorch) (75.1.0)\n",
            "Collecting sympy==1.13.1 (from torch->efficientnet_pytorch)\n",
            "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->efficientnet_pytorch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\envs\\testenv\\lib\\site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.5)\n",
            "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
            "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.8/204.1 MB 3.7 MB/s eta 0:00:55\n",
            "   ---------------------------------------- 1.6/204.1 MB 4.0 MB/s eta 0:00:51\n",
            "    --------------------------------------- 2.6/204.1 MB 4.3 MB/s eta 0:00:47\n",
            "    --------------------------------------- 3.7/204.1 MB 4.3 MB/s eta 0:00:47\n",
            "    --------------------------------------- 4.5/204.1 MB 4.4 MB/s eta 0:00:46\n",
            "   - -------------------------------------- 5.2/204.1 MB 4.2 MB/s eta 0:00:47\n",
            "   - -------------------------------------- 6.3/204.1 MB 4.3 MB/s eta 0:00:46\n",
            "   - -------------------------------------- 7.3/204.1 MB 4.4 MB/s eta 0:00:45\n",
            "   - -------------------------------------- 8.4/204.1 MB 4.4 MB/s eta 0:00:45\n",
            "   - -------------------------------------- 9.7/204.1 MB 4.6 MB/s eta 0:00:43\n",
            "   -- ------------------------------------- 10.7/204.1 MB 4.6 MB/s eta 0:00:43\n",
            "   -- ------------------------------------- 11.3/204.1 MB 4.5 MB/s eta 0:00:43\n",
            "   -- ------------------------------------- 12.6/204.1 MB 4.6 MB/s eta 0:00:42\n",
            "   -- ------------------------------------- 13.9/204.1 MB 4.7 MB/s eta 0:00:41\n",
            "   -- ------------------------------------- 15.2/204.1 MB 4.8 MB/s eta 0:00:40\n",
            "   --- ------------------------------------ 16.5/204.1 MB 4.8 MB/s eta 0:00:39\n",
            "   --- ------------------------------------ 17.6/204.1 MB 4.9 MB/s eta 0:00:39\n",
            "   --- ------------------------------------ 19.1/204.1 MB 5.0 MB/s eta 0:00:37\n",
            "   ---- ----------------------------------- 20.4/204.1 MB 5.1 MB/s eta 0:00:37\n",
            "   ---- ----------------------------------- 21.5/204.1 MB 5.1 MB/s eta 0:00:36\n",
            "   ---- ----------------------------------- 22.8/204.1 MB 5.1 MB/s eta 0:00:36\n",
            "   ---- ----------------------------------- 24.1/204.1 MB 5.2 MB/s eta 0:00:35\n",
            "   ---- ----------------------------------- 25.4/204.1 MB 5.2 MB/s eta 0:00:35\n",
            "   ----- ---------------------------------- 26.7/204.1 MB 5.2 MB/s eta 0:00:34\n",
            "   ----- ---------------------------------- 28.0/204.1 MB 5.3 MB/s eta 0:00:34\n",
            "   ----- ---------------------------------- 29.4/204.1 MB 5.3 MB/s eta 0:00:33\n",
            "   ------ --------------------------------- 30.7/204.1 MB 5.4 MB/s eta 0:00:33\n",
            "   ------ --------------------------------- 32.0/204.1 MB 5.4 MB/s eta 0:00:32\n",
            "   ------ --------------------------------- 33.0/204.1 MB 5.4 MB/s eta 0:00:32\n",
            "   ------ --------------------------------- 34.1/204.1 MB 5.4 MB/s eta 0:00:32\n",
            "   ------ --------------------------------- 35.4/204.1 MB 5.4 MB/s eta 0:00:32\n",
            "   ------- -------------------------------- 36.7/204.1 MB 5.4 MB/s eta 0:00:31\n",
            "   ------- -------------------------------- 37.7/204.1 MB 5.4 MB/s eta 0:00:31\n",
            "   ------- -------------------------------- 38.8/204.1 MB 5.4 MB/s eta 0:00:31\n",
            "   ------- -------------------------------- 39.6/204.1 MB 5.4 MB/s eta 0:00:31\n",
            "   ------- -------------------------------- 39.8/204.1 MB 5.3 MB/s eta 0:00:32\n",
            "   ------- -------------------------------- 40.1/204.1 MB 5.2 MB/s eta 0:00:32\n",
            "   ------- -------------------------------- 40.6/204.1 MB 5.1 MB/s eta 0:00:33\n",
            "   -------- ------------------------------- 40.9/204.1 MB 5.0 MB/s eta 0:00:33\n",
            "   -------- ------------------------------- 41.4/204.1 MB 5.0 MB/s eta 0:00:33\n",
            "   -------- ------------------------------- 41.9/204.1 MB 4.9 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 42.5/204.1 MB 4.8 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 42.7/204.1 MB 4.8 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 43.8/204.1 MB 4.7 MB/s eta 0:00:34\n",
            "   -------- ------------------------------- 45.1/204.1 MB 4.7 MB/s eta 0:00:34\n",
            "   --------- ------------------------------ 46.1/204.1 MB 4.8 MB/s eta 0:00:34\n",
            "   --------- ------------------------------ 47.4/204.1 MB 4.8 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 48.5/204.1 MB 4.8 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 49.8/204.1 MB 4.8 MB/s eta 0:00:33\n",
            "   --------- ------------------------------ 50.9/204.1 MB 4.8 MB/s eta 0:00:32\n",
            "   ---------- ----------------------------- 51.9/204.1 MB 4.8 MB/s eta 0:00:32\n",
            "   ---------- ----------------------------- 53.2/204.1 MB 4.8 MB/s eta 0:00:32\n",
            "   ---------- ----------------------------- 54.3/204.1 MB 4.9 MB/s eta 0:00:31\n",
            "   ---------- ----------------------------- 55.6/204.1 MB 4.9 MB/s eta 0:00:31\n",
            "   ----------- ---------------------------- 56.6/204.1 MB 4.9 MB/s eta 0:00:31\n",
            "   ----------- ---------------------------- 57.9/204.1 MB 4.9 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 59.2/204.1 MB 4.9 MB/s eta 0:00:30\n",
            "   ----------- ---------------------------- 60.6/204.1 MB 4.9 MB/s eta 0:00:30\n",
            "   ------------ --------------------------- 61.9/204.1 MB 5.0 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 63.2/204.1 MB 5.0 MB/s eta 0:00:29\n",
            "   ------------ --------------------------- 64.5/204.1 MB 5.0 MB/s eta 0:00:28\n",
            "   ------------ --------------------------- 65.5/204.1 MB 5.0 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 66.8/204.1 MB 5.0 MB/s eta 0:00:28\n",
            "   ------------- -------------------------- 68.2/204.1 MB 5.0 MB/s eta 0:00:27\n",
            "   ------------- -------------------------- 69.5/204.1 MB 5.1 MB/s eta 0:00:27\n",
            "   ------------- -------------------------- 70.5/204.1 MB 5.1 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 71.6/204.1 MB 5.0 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 71.8/204.1 MB 5.0 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 72.4/204.1 MB 5.0 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 72.6/204.1 MB 4.9 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 73.1/204.1 MB 4.9 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 73.7/204.1 MB 4.8 MB/s eta 0:00:27\n",
            "   -------------- ------------------------- 73.9/204.1 MB 4.8 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 74.4/204.1 MB 4.8 MB/s eta 0:00:28\n",
            "   -------------- ------------------------- 75.5/204.1 MB 4.8 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 76.8/204.1 MB 4.8 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 77.9/204.1 MB 4.8 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 79.2/204.1 MB 4.8 MB/s eta 0:00:27\n",
            "   --------------- ------------------------ 80.5/204.1 MB 4.8 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 81.8/204.1 MB 4.8 MB/s eta 0:00:26\n",
            "   ---------------- ----------------------- 83.1/204.1 MB 4.9 MB/s eta 0:00:25\n",
            "   ---------------- ----------------------- 84.4/204.1 MB 4.9 MB/s eta 0:00:25\n",
            "   ---------------- ----------------------- 85.7/204.1 MB 4.9 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 87.0/204.1 MB 4.9 MB/s eta 0:00:24\n",
            "   ----------------- ---------------------- 87.3/204.1 MB 4.9 MB/s eta 0:00:24\n",
            "   ----------------- ---------------------- 87.8/204.1 MB 4.8 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 88.3/204.1 MB 4.8 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 88.6/204.1 MB 4.8 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 89.1/204.1 MB 4.7 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 89.7/204.1 MB 4.7 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 90.2/204.1 MB 4.7 MB/s eta 0:00:25\n",
            "   ----------------- ---------------------- 91.2/204.1 MB 4.7 MB/s eta 0:00:25\n",
            "   ------------------ --------------------- 92.5/204.1 MB 4.7 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 93.6/204.1 MB 4.7 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 94.9/204.1 MB 4.7 MB/s eta 0:00:24\n",
            "   ------------------ --------------------- 95.9/204.1 MB 4.7 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 97.3/204.1 MB 4.7 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 98.6/204.1 MB 4.8 MB/s eta 0:00:23\n",
            "   ------------------- -------------------- 99.9/204.1 MB 4.8 MB/s eta 0:00:22\n",
            "   ------------------- -------------------- 100.9/204.1 MB 4.8 MB/s eta 0:00:22\n",
            "   -------------------- ------------------- 102.2/204.1 MB 4.8 MB/s eta 0:00:22\n",
            "   -------------------- ------------------- 103.5/204.1 MB 4.8 MB/s eta 0:00:21\n",
            "   -------------------- ------------------- 104.9/204.1 MB 4.8 MB/s eta 0:00:21\n",
            "   -------------------- ------------------- 106.2/204.1 MB 4.8 MB/s eta 0:00:21\n",
            "   --------------------- ------------------ 107.5/204.1 MB 4.8 MB/s eta 0:00:20\n",
            "   --------------------- ------------------ 108.8/204.1 MB 4.9 MB/s eta 0:00:20\n",
            "   --------------------- ------------------ 110.1/204.1 MB 4.9 MB/s eta 0:00:20\n",
            "   --------------------- ------------------ 111.4/204.1 MB 4.9 MB/s eta 0:00:20\n",
            "   ---------------------- ----------------- 112.5/204.1 MB 4.9 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 114.0/204.1 MB 4.9 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 115.3/204.1 MB 4.9 MB/s eta 0:00:19\n",
            "   ---------------------- ----------------- 116.7/204.1 MB 4.9 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 118.0/204.1 MB 4.9 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 119.3/204.1 MB 4.9 MB/s eta 0:00:18\n",
            "   ----------------------- ---------------- 120.6/204.1 MB 5.0 MB/s eta 0:00:17\n",
            "   ----------------------- ---------------- 122.2/204.1 MB 5.0 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 123.5/204.1 MB 5.0 MB/s eta 0:00:17\n",
            "   ------------------------ --------------- 124.5/204.1 MB 5.0 MB/s eta 0:00:16\n",
            "   ------------------------ --------------- 125.3/204.1 MB 5.0 MB/s eta 0:00:16\n",
            "   ------------------------ --------------- 126.1/204.1 MB 5.0 MB/s eta 0:00:16\n",
            "   ------------------------ --------------- 127.1/204.1 MB 5.0 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 127.7/204.1 MB 5.0 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 128.5/204.1 MB 4.9 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 129.5/204.1 MB 4.9 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 130.0/204.1 MB 4.9 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 131.1/204.1 MB 4.9 MB/s eta 0:00:15\n",
            "   ------------------------- -------------- 131.3/204.1 MB 4.9 MB/s eta 0:00:15\n",
            "   ------------------------- -------------- 131.3/204.1 MB 4.9 MB/s eta 0:00:15\n",
            "   ------------------------- -------------- 131.6/204.1 MB 4.8 MB/s eta 0:00:15\n",
            "   ------------------------- -------------- 131.9/204.1 MB 4.8 MB/s eta 0:00:15\n",
            "   ------------------------- -------------- 132.1/204.1 MB 4.8 MB/s eta 0:00:16\n",
            "   ------------------------- -------------- 132.6/204.1 MB 4.7 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 132.9/204.1 MB 4.7 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 133.2/204.1 MB 4.7 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 133.4/204.1 MB 4.7 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 133.7/204.1 MB 4.6 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 134.2/204.1 MB 4.6 MB/s eta 0:00:16\n",
            "   -------------------------- ------------- 135.3/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 136.1/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 136.8/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 137.4/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   -------------------------- ------------- 137.6/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 138.1/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 138.9/204.1 MB 4.6 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 139.5/204.1 MB 4.5 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 139.7/204.1 MB 4.5 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 140.2/204.1 MB 4.5 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 140.8/204.1 MB 4.5 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 141.3/204.1 MB 4.5 MB/s eta 0:00:15\n",
            "   --------------------------- ------------ 142.1/204.1 MB 4.5 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 142.3/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   --------------------------- ------------ 142.9/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 143.4/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 143.9/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 144.7/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 145.0/204.1 MB 4.4 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 145.5/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 146.3/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.1/204.1 MB 4.3 MB/s eta 0:00:14\n",
            "   ---------------------------- ----------- 147.8/204.1 MB 3.9 MB/s eta 0:00:15\n",
            "   ----------------------------- ---------- 148.9/204.1 MB 3.9 MB/s eta 0:00:15\n",
            "   ----------------------------- ---------- 149.7/204.1 MB 3.9 MB/s eta 0:00:15\n",
            "   ----------------------------- ---------- 150.5/204.1 MB 3.9 MB/s eta 0:00:14\n",
            "   ----------------------------- ---------- 151.3/204.1 MB 3.8 MB/s eta 0:00:14\n",
            "   ----------------------------- ---------- 151.8/204.1 MB 3.8 MB/s eta 0:00:14\n",
            "   ----------------------------- ---------- 152.8/204.1 MB 3.8 MB/s eta 0:00:14\n",
            "   ------------------------------ --------- 154.1/204.1 MB 3.8 MB/s eta 0:00:14\n",
            "   ------------------------------ --------- 155.2/204.1 MB 3.9 MB/s eta 0:00:13\n",
            "   ------------------------------ --------- 156.5/204.1 MB 3.9 MB/s eta 0:00:13\n",
            "   ------------------------------ --------- 157.5/204.1 MB 3.9 MB/s eta 0:00:12\n",
            "   ------------------------------- -------- 158.9/204.1 MB 3.9 MB/s eta 0:00:12\n",
            "   ------------------------------- -------- 159.9/204.1 MB 3.9 MB/s eta 0:00:12\n",
            "   ------------------------------- -------- 161.2/204.1 MB 4.0 MB/s eta 0:00:11\n",
            "   ------------------------------- -------- 162.3/204.1 MB 4.0 MB/s eta 0:00:11\n",
            "   ------------------------------- -------- 162.8/204.1 MB 4.0 MB/s eta 0:00:11\n",
            "   -------------------------------- ------- 163.6/204.1 MB 4.0 MB/s eta 0:00:11\n",
            "   -------------------------------- ------- 164.1/204.1 MB 4.0 MB/s eta 0:00:11\n",
            "   -------------------------------- ------- 164.9/204.1 MB 4.0 MB/s eta 0:00:10\n",
            "   -------------------------------- ------- 165.4/204.1 MB 4.0 MB/s eta 0:00:10\n",
            "   -------------------------------- ------- 166.2/204.1 MB 3.9 MB/s eta 0:00:10\n",
            "   -------------------------------- ------- 167.0/204.1 MB 3.9 MB/s eta 0:00:10\n",
            "   -------------------------------- ------- 168.0/204.1 MB 3.9 MB/s eta 0:00:10\n",
            "   --------------------------------- ------ 168.8/204.1 MB 3.9 MB/s eta 0:00:10\n",
            "   --------------------------------- ------ 170.1/204.1 MB 3.9 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 171.4/204.1 MB 3.9 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 171.7/204.1 MB 3.9 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 172.2/204.1 MB 3.9 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 172.8/204.1 MB 3.8 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 172.8/204.1 MB 3.8 MB/s eta 0:00:09\n",
            "   --------------------------------- ------ 173.0/204.1 MB 3.8 MB/s eta 0:00:09\n",
            "   ---------------------------------- ----- 173.5/204.1 MB 3.7 MB/s eta 0:00:09\n",
            "   ---------------------------------- ----- 173.8/204.1 MB 3.7 MB/s eta 0:00:09\n",
            "   ---------------------------------- ----- 174.3/204.1 MB 3.7 MB/s eta 0:00:09\n",
            "   ---------------------------------- ----- 174.9/204.1 MB 3.6 MB/s eta 0:00:09\n",
            "   ---------------------------------- ----- 175.9/204.1 MB 3.6 MB/s eta 0:00:08\n",
            "   ---------------------------------- ----- 176.9/204.1 MB 3.6 MB/s eta 0:00:08\n",
            "   ---------------------------------- ----- 178.0/204.1 MB 3.6 MB/s eta 0:00:08\n",
            "   ----------------------------------- ---- 179.3/204.1 MB 3.6 MB/s eta 0:00:07\n",
            "   ----------------------------------- ---- 180.4/204.1 MB 3.6 MB/s eta 0:00:07\n",
            "   ----------------------------------- ---- 181.4/204.1 MB 3.7 MB/s eta 0:00:07\n",
            "   ----------------------------------- ---- 182.2/204.1 MB 3.7 MB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 182.5/204.1 MB 3.7 MB/s eta 0:00:06\n",
            "   ----------------------------------- ---- 183.0/204.1 MB 3.7 MB/s eta 0:00:06\n",
            "   ------------------------------------ --- 183.8/204.1 MB 3.7 MB/s eta 0:00:06\n",
            "   ------------------------------------ --- 184.5/204.1 MB 3.7 MB/s eta 0:00:06\n",
            "   ------------------------------------ --- 185.9/204.1 MB 3.7 MB/s eta 0:00:05\n",
            "   ------------------------------------ --- 187.2/204.1 MB 3.7 MB/s eta 0:00:05\n",
            "   ------------------------------------ --- 188.2/204.1 MB 3.7 MB/s eta 0:00:05\n",
            "   ------------------------------------- -- 189.5/204.1 MB 3.7 MB/s eta 0:00:04\n",
            "   ------------------------------------- -- 190.6/204.1 MB 3.7 MB/s eta 0:00:04\n",
            "   ------------------------------------- -- 192.2/204.1 MB 3.7 MB/s eta 0:00:04\n",
            "   ------------------------------------- -- 193.2/204.1 MB 3.7 MB/s eta 0:00:03\n",
            "   -------------------------------------- - 194.5/204.1 MB 3.7 MB/s eta 0:00:03\n",
            "   -------------------------------------- - 195.6/204.1 MB 3.7 MB/s eta 0:00:03\n",
            "   -------------------------------------- - 196.9/204.1 MB 3.7 MB/s eta 0:00:02\n",
            "   -------------------------------------- - 198.2/204.1 MB 3.7 MB/s eta 0:00:02\n",
            "   ---------------------------------------  199.2/204.1 MB 3.7 MB/s eta 0:00:02\n",
            "   ---------------------------------------  200.8/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  202.1/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.2/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------  203.9/204.1 MB 3.8 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 204.1/204.1 MB 3.5 MB/s eta 0:00:00\n",
            "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
            "   ------------------ --------------------- 0.8/1.7 MB 2.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 1.6/1.7 MB 2.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.7/1.7 MB 2.6 MB/s eta 0:00:00\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Building wheels for collected packages: efficientnet_pytorch\n",
            "  Building wheel for efficientnet_pytorch (setup.py): started\n",
            "  Building wheel for efficientnet_pytorch (setup.py): finished with status 'done'\n",
            "  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16458 sha256=4b31a547879cb782c2e5ff65dc091ac699ad7b9b3044006820bab8b345023782\n",
            "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\9c\\3f\\43\\e6271c7026fe08c185da2be23c98c8e87477d3db63f41f32ad\n",
            "Successfully built efficientnet_pytorch\n",
            "Installing collected packages: mpmath, sympy, networkx, jinja2, torch, efficientnet_pytorch\n",
            "Successfully installed efficientnet_pytorch-0.7.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfA3F2Y5XV_0",
        "outputId": "25b1954a-7948-4ca5-8a31-4590310d71af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 48620305.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-100-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# Define data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
        "])\n",
        "\n",
        "#Download the pre-trained EfficientNet model\n",
        "model_name = 'efficientnet-b0'\n",
        "backbone = EfficientNet.from_pretrained(model_name, num_classes=1000)\n",
        "\n",
        "#Add a dense layer on top of the EfficientNet backbone\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.fc = nn.Linear(1000, 100)  # Adjust output size for CIFAR-100 (100)\n",
        "        self.dropout = nn.Dropout(0.5)  # Adding dropout for regularization\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an instance of the CustomModel\n",
        "model = CustomModel(backbone)\n",
        "\n",
        "# Define your data loaders\n",
        "train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Splitting a validation set from the test dataset\n",
        "test_size = len(test_dataset) // 2\n",
        "validation_dataset, test_dataset = torch.utils.data.random_split(test_dataset, [test_size, test_size])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "#Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward   ()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        accuracy = correct / total\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4jX8B8jYeJ9j"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[0;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive/My Drive/models/my_model.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/models/my_model.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT8XAXOLK_bv",
        "outputId": "884da296-e4bf-4030-b744-8d7b816d16fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (backbone): EfficientNet(\n",
              "    (_conv_stem): Conv2dStaticSamePadding(\n",
              "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "      (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "    )\n",
              "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_blocks): ModuleList(\n",
              "      (0): MBConvBlock(\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (1): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (2): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (3): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (4): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (5): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "          (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (6-7): 2 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (8): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (9-10): 2 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (11): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (12-14): 3 x MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "      (15): MBConvBlock(\n",
              "        (_expand_conv): Conv2dStaticSamePadding(\n",
              "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "          (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "        )\n",
              "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_se_reduce): Conv2dStaticSamePadding(\n",
              "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_se_expand): Conv2dStaticSamePadding(\n",
              "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_project_conv): Conv2dStaticSamePadding(\n",
              "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "          (static_padding): Identity()\n",
              "        )\n",
              "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "        (_swish): MemoryEfficientSwish()\n",
              "      )\n",
              "    )\n",
              "    (_conv_head): Conv2dStaticSamePadding(\n",
              "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "      (static_padding): Identity()\n",
              "    )\n",
              "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "    (_dropout): Dropout(p=0.2, inplace=False)\n",
              "    (_fc): Linear(in_features=1280, out_features=1000, bias=True)\n",
              "    (_swish): MemoryEfficientSwish()\n",
              "  )\n",
              "  (fc): Linear(in_features=1000, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "# Path to your .pth file in Google Drive\n",
        "file_path = '/content/drive/My Drive/final_model.pth'  # Replace with your file path\n",
        "\n",
        "\n",
        "# Define your CustomModel class\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super(CustomModel, self).__init__()\n",
        "        self.backbone = backbone\n",
        "        self.fc = nn.Linear(1000, 100)  # Ensure the output size matches the saved model\n",
        "        self.dropout = nn.Dropout(0.5)  # Ensure the dropout rate matches the saved model\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Download the pre-trained EfficientNet model\n",
        "model_name = 'efficientnet-b0'\n",
        "backbone = EfficientNet.from_pretrained(model_name, num_classes=1000)\n",
        "\n",
        "# Create an instance of CustomModel with the pre-trained EfficientNet backbone\n",
        "model = CustomModel(backbone)\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "model.load_state_dict(torch.load(file_path))\n",
        "\n",
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Move the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsZdi8YYOhNk",
        "outputId": "5da25e79-7700-44c0-8756-e26a1094e86f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Training Accuracy: 0.7386, Validation Accuracy: 0.8478\n",
            "Epoch 2/5, Training Accuracy: 0.7391, Validation Accuracy: 0.8462\n",
            "Epoch 3/5, Training Accuracy: 0.7404, Validation Accuracy: 0.8488\n",
            "Epoch 4/5, Training Accuracy: 0.7415, Validation Accuracy: 0.8528\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_train = 0\n",
        "    correct_train = 0\n",
        "\n",
        "    # Training loop\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    train_accuracy = ((correct_train) / total_train)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        for inputs, labels in validation_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_val += labels.size(0)\n",
        "            correct_val += (predicted == labels).sum().item()\n",
        "\n",
        "    val_accuracy = correct_val / total_val\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Training Accuracy: {train_accuracy:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G3InXW5gEsQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "torch.save(model.state_dict(), '/content/drive/My Drive/last.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 985
        },
        "id": "D3tCJrwRTHEY",
        "outputId": "c46adbb5-ea8f-4085-dcd6-87d4518dab8b"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'matplotlib'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Function to display random images with predictions\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Function to display random images with predictions\n",
        "def display_random_images(images, labels, predictions, num_images=15):\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    indices = np.random.choice(len(images), num_images, replace=False)  # Select random indices\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.subplot(3, 5, i + 1)\n",
        "        plt.imshow(np.transpose(images[idx].cpu().numpy(), (1, 2, 0)))\n",
        "        plt.title(f\"Prediction: {predictions[idx]}, Ground Truth: {labels[idx]}\")\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of test images and labels\n",
        "batch_size = 25\n",
        "test_iterator = iter(test_loader)\n",
        "images, labels = next(test_iterator)\n",
        "\n",
        "# Move images to the device\n",
        "images = images.to(device)\n",
        "\n",
        "# Perform inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Display random images with predictions and ground truth labels\n",
        "display_random_images(images, labels, predicted, num_images=15)  # Change num_images as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dWvoZ_TTvIO",
        "outputId": "49526422-2cf8-4b3d-8891-f77c8e0a77ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8598\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test dataset\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbR0Y_fVWoRX",
        "outputId": "dcf89a1b-170f-436e-9d90-6a6d01eb5c2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8560\n"
          ]
        }
      ],
      "source": [
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Iterate over the test dataset\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cbCvRzsvnQR"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/My Drive/last.pth')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "testenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
